{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-03T01:49:17.247037Z",
     "start_time": "2024-01-03T01:49:17.225737Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "key = os.getenv('AZURE_SEARCH_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from fastbook import search_images_bing\n",
    "from PIL import Image\n",
    "from fastdownload import download_url\n",
    "\n",
    "res = search_images_bing(key, 'grizzly bear')\n",
    "images = res.attrgot('contentUrl')\n",
    "dest = './images/grizzly.jpg'\n",
    "download_url(images[0], dest)\n",
    "\n",
    "im = Image.open(dest)\n",
    "im.to_thumb(128,128)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7831e48b9892ad20",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from fastai.vision.utils import download_images\n",
    "from pathlib import Path\n",
    "\n",
    "bears_types = ('grizzly', 'black', 'teddy')\n",
    "path = Path('bears')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T01:49:23.714883Z",
     "start_time": "2024-01-03T01:49:21.296577Z"
    }
   },
   "id": "2a2894a429102a07",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "이미지 다운로드"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44143f27ec558e4b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if not path.exists():\n",
    "    path.mkdir()\n",
    "    for o in bears_types:\n",
    "        dest = (path/o)\n",
    "        dest.mkdir(exist_ok=True)\n",
    "        res = search_images_bing(key, f'{o} bear')\n",
    "        download_images(dest, urls=res.attrgot('contentUrl'))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49779e33c87bd59e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(#0) []"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.vision.utils import verify_images\n",
    "from fastai.data.transforms import get_image_files\n",
    "\n",
    "fns = get_image_files(path) # get all files in path\n",
    "failed = verify_images(fns) # verify all files in path\n",
    "failed.map(Path.unlink) # delete all failed files"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T01:49:31.678512Z",
     "start_time": "2024-01-03T01:49:28.620767Z"
    }
   },
   "id": "b02040acee36f6f0",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from fastai.vision.augment import Resize, __all__\n",
    "from fastai.data.transforms import RandomSplitter, parent_label\n",
    "from fastai.vision.data import ImageBlock\n",
    "from fastai.data.block import DataBlock, CategoryBlock\n",
    "from fastai.data.transforms import get_image_files\n",
    "\n",
    "bears = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), # 1번째는 독립변수 (입력 데이터), 2번째는 종속변수 (독립변수를 활용해 예측할 대상)\n",
    "    get_items=get_image_files,\n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label, # 독립변수는 x, 종속변수는 y\n",
    "    item_tfms=Resize(224)\n",
    ")\n",
    "\n",
    "data_loaders = bears.dataloaders(path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T01:49:42.471990Z",
     "start_time": "2024-01-03T01:49:41.618986Z"
    }
   },
   "id": "4b9ef8dc942932e7",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_loaders.show_batch(max_n=4, nrows=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9c8e30ec6754400",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "사진 이미지가 다를 경우 학습에 불리 할 수 있다. 그래서 이미지를 표준화 시켜준다. (Squish = 찌그러트림)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9044177ca5208cfc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "bears = bears.new(item_tfms=Resize(128, ResizeMethod.Squish))\n",
    "data_loaders = bears.dataloaders(path)\n",
    "data_loaders.show_batch(max_n=9, nrows=3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8700108eab27c87"
  },
  {
   "cell_type": "markdown",
   "source": [
    "랜덤으로 각 epoch 마다 같은 이미지 속 다양한 부분을 학습 시킴."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c1c2aa843d0056d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "bears = bears.new(item_tfms=RandomResizedCrop(128, min_scale=0.3))\n",
    "data_loaders = bears.dataloaders(path)\n",
    "data_loaders.show_batch(max_n=4, nrows=1, unique=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e22e9abc1deb027",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "데이터 증강: 입력 데이터를 임의로 변경해 새로운 데이터를 생성하는 기법."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ccc969a36dddc59"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "bears = bears.new(item_tfms=Resize(128), batch_tfms=aug_transforms(mult=4))\n",
    "data_loaders = bears.dataloaders(path)\n",
    "data_loaders.train.show_batch(max_n=8, nrows=2, unique=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9598149885e356bc",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "모델 훈련과 훈련된 모델을 이용한 데이터 정리"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1ded7bb54a66e36"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not do one pass in your dataloader, there is something wrong in it. Please see the stack trace below:\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::_linalg_solve_ex.result' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mfastai\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvision\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mall\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m      3\u001B[0m bears \u001B[38;5;241m=\u001B[39m bears\u001B[38;5;241m.\u001B[39mnew(item_tfms\u001B[38;5;241m=\u001B[39mRandomResizedCrop(\u001B[38;5;241m224\u001B[39m, min_scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m), batch_tfms\u001B[38;5;241m=\u001B[39maug_transforms())\n\u001B[0;32m----> 4\u001B[0m data_loaders \u001B[38;5;241m=\u001B[39m \u001B[43mbears\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloaders\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m learn \u001B[38;5;241m=\u001B[39m vision_learner(data_loaders, resnet18, metrics\u001B[38;5;241m=\u001B[39merror_rate)\n\u001B[1;32m      7\u001B[0m learn\u001B[38;5;241m.\u001B[39mfine_tune(\u001B[38;5;241m4\u001B[39m)\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastai/data/block.py:157\u001B[0m, in \u001B[0;36mDataBlock.dataloaders\u001B[0;34m(self, source, path, verbose, **kwargs)\u001B[0m\n\u001B[1;32m    155\u001B[0m dsets \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdatasets(source, verbose\u001B[38;5;241m=\u001B[39mverbose)\n\u001B[1;32m    156\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdls_kwargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mverbose\u001B[39m\u001B[38;5;124m'\u001B[39m: verbose}\n\u001B[0;32m--> 157\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdsets\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloaders\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mafter_item\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem_tfms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mafter_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_tfms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastai/data/core.py:337\u001B[0m, in \u001B[0;36mFilteredBase.dataloaders\u001B[0;34m(self, bs, shuffle_train, shuffle, val_shuffle, n, path, dl_type, dl_kwargs, device, drop_last, val_bs, **kwargs)\u001B[0m\n\u001B[1;32m    335\u001B[0m dl \u001B[38;5;241m=\u001B[39m dl_type(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msubset(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmerge(kwargs,def_kwargs, dl_kwargs[\u001B[38;5;241m0\u001B[39m]))\n\u001B[1;32m    336\u001B[0m def_kwargs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbs\u001B[39m\u001B[38;5;124m'\u001B[39m:bs \u001B[38;5;28;01mif\u001B[39;00m val_bs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m val_bs,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mshuffle\u001B[39m\u001B[38;5;124m'\u001B[39m:val_shuffle,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;28;01mNone\u001B[39;00m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdrop_last\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;28;01mFalse\u001B[39;00m}\n\u001B[0;32m--> 337\u001B[0m dls \u001B[38;5;241m=\u001B[39m [dl] \u001B[38;5;241m+\u001B[39m \u001B[43m[\u001B[49m\u001B[43mdl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnew\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmerge\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdef_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43mval_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdl_kwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    338\u001B[0m \u001B[43m              \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_subsets\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    339\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dbunch_type(\u001B[38;5;241m*\u001B[39mdls, path\u001B[38;5;241m=\u001B[39mpath, device\u001B[38;5;241m=\u001B[39mdevice)\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastai/data/core.py:337\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    335\u001B[0m dl \u001B[38;5;241m=\u001B[39m dl_type(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msubset(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmerge(kwargs,def_kwargs, dl_kwargs[\u001B[38;5;241m0\u001B[39m]))\n\u001B[1;32m    336\u001B[0m def_kwargs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbs\u001B[39m\u001B[38;5;124m'\u001B[39m:bs \u001B[38;5;28;01mif\u001B[39;00m val_bs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m val_bs,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mshuffle\u001B[39m\u001B[38;5;124m'\u001B[39m:val_shuffle,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;28;01mNone\u001B[39;00m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdrop_last\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;28;01mFalse\u001B[39;00m}\n\u001B[0;32m--> 337\u001B[0m dls \u001B[38;5;241m=\u001B[39m [dl] \u001B[38;5;241m+\u001B[39m [\u001B[43mdl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnew\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmerge\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdef_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43mval_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdl_kwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    338\u001B[0m               \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_subsets)]\n\u001B[1;32m    339\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dbunch_type(\u001B[38;5;241m*\u001B[39mdls, path\u001B[38;5;241m=\u001B[39mpath, device\u001B[38;5;241m=\u001B[39mdevice)\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastai/data/core.py:97\u001B[0m, in \u001B[0;36mTfmdDL.new\u001B[0;34m(self, dataset, cls, **kwargs)\u001B[0m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_n_inp\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_types\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 97\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_one_pass\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     98\u001B[0m         res\u001B[38;5;241m.\u001B[39m_n_inp,res\u001B[38;5;241m.\u001B[39m_types \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_inp,\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_types\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e: \n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastai/data/core.py:80\u001B[0m, in \u001B[0;36mTfmdDL._one_pass\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     78\u001B[0m b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdo_batch([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdo_item(\u001B[38;5;28;01mNone\u001B[39;00m)])\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m: b \u001B[38;5;241m=\u001B[39m to_device(b, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m---> 80\u001B[0m its \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mafter_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_inp \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(its, (\u001B[38;5;28mlist\u001B[39m,\u001B[38;5;28mtuple\u001B[39m)) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(its)\u001B[38;5;241m==\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(its)\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_types \u001B[38;5;241m=\u001B[39m explode_types(its)\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastcore/transform.py:208\u001B[0m, in \u001B[0;36mPipeline.__call__\u001B[0;34m(self, o)\u001B[0m\n\u001B[0;32m--> 208\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, o): \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcompose_tfms\u001B[49m\u001B[43m(\u001B[49m\u001B[43mo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtfms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit_idx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastcore/transform.py:158\u001B[0m, in \u001B[0;36mcompose_tfms\u001B[0;34m(x, tfms, is_enc, reverse, **kwargs)\u001B[0m\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m tfms:\n\u001B[1;32m    157\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_enc: f \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mdecode\n\u001B[0;32m--> 158\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastai/vision/augment.py:49\u001B[0m, in \u001B[0;36mRandTransform.__call__\u001B[0;34m(self, b, split_idx, **kwargs)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \n\u001B[1;32m     44\u001B[0m     b, \n\u001B[1;32m     45\u001B[0m     split_idx:\u001B[38;5;28mint\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;66;03m# Index of the train/valid dataset\u001B[39;00m\n\u001B[1;32m     46\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m     47\u001B[0m ):\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbefore_call(b, split_idx\u001B[38;5;241m=\u001B[39msplit_idx)\n\u001B[0;32m---> 49\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdo \u001B[38;5;28;01melse\u001B[39;00m b\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastcore/transform.py:81\u001B[0m, in \u001B[0;36mTransform.__call__\u001B[0;34m(self, x, **kwargs)\u001B[0m\n\u001B[0;32m---> 81\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs): \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mencodes\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastcore/transform.py:91\u001B[0m, in \u001B[0;36mTransform._call\u001B[0;34m(self, fn, x, split_idx, **kwargs)\u001B[0m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn, x, split_idx\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     90\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m split_idx\u001B[38;5;241m!=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msplit_idx \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msplit_idx \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m: \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[0;32m---> 91\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastcore/transform.py:98\u001B[0m, in \u001B[0;36mTransform._do_call\u001B[0;34m(self, f, x, **kwargs)\u001B[0m\n\u001B[1;32m     96\u001B[0m     ret \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mreturns(x) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(f,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreturns\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     97\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m retain_type(f(x, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs), x, ret)\n\u001B[0;32m---> 98\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_call(f, x_, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;28;01mfor\u001B[39;00m x_ \u001B[38;5;129;01min\u001B[39;00m x)\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m retain_type(res, x)\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastcore/transform.py:98\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     96\u001B[0m     ret \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mreturns(x) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(f,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreturns\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     97\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m retain_type(f(x, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs), x, ret)\n\u001B[0;32m---> 98\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x_ \u001B[38;5;129;01min\u001B[39;00m x)\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m retain_type(res, x)\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastcore/transform.py:97\u001B[0m, in \u001B[0;36mTransform._do_call\u001B[0;34m(self, f, x, **kwargs)\u001B[0m\n\u001B[1;32m     95\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m f \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m: \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[1;32m     96\u001B[0m     ret \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mreturns(x) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(f,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreturns\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m---> 97\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m retain_type(\u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m, x, ret)\n\u001B[1;32m     98\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_call(f, x_, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;28;01mfor\u001B[39;00m x_ \u001B[38;5;129;01min\u001B[39;00m x)\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m retain_type(res, x)\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastcore/dispatch.py:120\u001B[0m, in \u001B[0;36mTypeDispatch.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minst \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m: f \u001B[38;5;241m=\u001B[39m MethodType(f, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minst)\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mowner \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m: f \u001B[38;5;241m=\u001B[39m MethodType(f, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mowner)\n\u001B[0;32m--> 120\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastai/vision/augment.py:501\u001B[0m, in \u001B[0;36mAffineCoordTfm.encodes\u001B[0;34m(self, x)\u001B[0m\n\u001B[0;32m--> 501\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mencodes\u001B[39m(\u001B[38;5;28mself\u001B[39m, x:TensorImage): \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_encode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastai/vision/augment.py:499\u001B[0m, in \u001B[0;36mAffineCoordTfm._encode\u001B[0;34m(self, x, mode, reverse)\u001B[0m\n\u001B[1;32m    497\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_encode\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, mode, reverse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    498\u001B[0m     coord_func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoord_fs)\u001B[38;5;241m==\u001B[39m\u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msplit_idx \u001B[38;5;28;01melse\u001B[39;00m partial(compose_tfms, tfms\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoord_fs, reverse\u001B[38;5;241m=\u001B[39mreverse)\n\u001B[0;32m--> 499\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maffine_coord\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcoord_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msz\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpad_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad_mode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malign_corners\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43malign_corners\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastai/vision/augment.py:390\u001B[0m, in \u001B[0;36maffine_coord\u001B[0;34m(x, mat, coord_tfm, sz, mode, pad_mode, align_corners)\u001B[0m\n\u001B[1;32m    388\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mat \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m: mat \u001B[38;5;241m=\u001B[39m _init_mat(x)[:,:\u001B[38;5;241m2\u001B[39m]\n\u001B[1;32m    389\u001B[0m coords \u001B[38;5;241m=\u001B[39m affine_grid(mat, x\u001B[38;5;241m.\u001B[39mshape[:\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m+\u001B[39m size, align_corners\u001B[38;5;241m=\u001B[39malign_corners)\n\u001B[0;32m--> 390\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m coord_tfm \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m: coords \u001B[38;5;241m=\u001B[39m \u001B[43mcoord_tfm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcoords\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    391\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m TensorImage(_grid_sample(x, coords, mode\u001B[38;5;241m=\u001B[39mmode, padding_mode\u001B[38;5;241m=\u001B[39mpad_mode, align_corners\u001B[38;5;241m=\u001B[39malign_corners))\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastcore/transform.py:158\u001B[0m, in \u001B[0;36mcompose_tfms\u001B[0;34m(x, tfms, is_enc, reverse, **kwargs)\u001B[0m\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m tfms:\n\u001B[1;32m    157\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_enc: f \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mdecode\n\u001B[0;32m--> 158\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastai/vision/augment.py:870\u001B[0m, in \u001B[0;36m_WarpCoord.__call__\u001B[0;34m(self, x, invert)\u001B[0m\n\u001B[1;32m    869\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, invert\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 870\u001B[0m     coeffs \u001B[38;5;241m=\u001B[39m find_coeffs(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarg_pts, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39morig_pts) \u001B[38;5;28;01mif\u001B[39;00m invert \u001B[38;5;28;01melse\u001B[39;00m \u001B[43mfind_coeffs\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43morig_pts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarg_pts\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    871\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m apply_perspective(x, coeffs)\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastai/vision/augment.py:834\u001B[0m, in \u001B[0;36mfind_coeffs\u001B[0;34m(p1, p2)\u001B[0m\n\u001B[1;32m    832\u001B[0m A \u001B[38;5;241m=\u001B[39m stack(m)\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    833\u001B[0m B \u001B[38;5;241m=\u001B[39m p1\u001B[38;5;241m.\u001B[39mview(p1\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m8\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m--> 834\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msolve\u001B[49m\u001B[43m(\u001B[49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43mB\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastai/vision/augment.py:817\u001B[0m, in \u001B[0;36msolve\u001B[0;34m(A, B)\u001B[0m\n\u001B[1;32m    816\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msolve\u001B[39m(A,B):\n\u001B[0;32m--> 817\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinalg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msolve\u001B[49m\u001B[43m(\u001B[49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43mB\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/fastai/torch_core.py:382\u001B[0m, in \u001B[0;36mTensorBase.__torch_function__\u001B[0;34m(cls, func, types, args, kwargs)\u001B[0m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mdebug \u001B[38;5;129;01mand\u001B[39;00m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__str__\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__repr__\u001B[39m\u001B[38;5;124m'\u001B[39m): \u001B[38;5;28mprint\u001B[39m(func, types, args, kwargs)\n\u001B[1;32m    381\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _torch_handled(args, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_opt, func): types \u001B[38;5;241m=\u001B[39m (torch\u001B[38;5;241m.\u001B[39mTensor,)\n\u001B[0;32m--> 382\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__torch_function__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mifnone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    383\u001B[0m dict_objs \u001B[38;5;241m=\u001B[39m _find_args(args) \u001B[38;5;28;01mif\u001B[39;00m args \u001B[38;5;28;01melse\u001B[39;00m _find_args(\u001B[38;5;28mlist\u001B[39m(kwargs\u001B[38;5;241m.\u001B[39mvalues()))\n\u001B[1;32m    384\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(\u001B[38;5;28mtype\u001B[39m(res),TensorBase) \u001B[38;5;129;01mand\u001B[39;00m dict_objs: res\u001B[38;5;241m.\u001B[39mset_meta(dict_objs[\u001B[38;5;241m0\u001B[39m],as_copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Repository/ML_Notes/venv/lib/python3.11/site-packages/torch/_tensor.py:1386\u001B[0m, in \u001B[0;36mTensor.__torch_function__\u001B[0;34m(cls, func, types, args, kwargs)\u001B[0m\n\u001B[1;32m   1383\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[1;32m   1385\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _C\u001B[38;5;241m.\u001B[39mDisableTorchFunctionSubclass():\n\u001B[0;32m-> 1386\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1387\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m func \u001B[38;5;129;01min\u001B[39;00m get_default_nowrap_functions():\n\u001B[1;32m   1388\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: The operator 'aten::_linalg_solve_ex.result' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "bears = bears.new(item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms())\n",
    "data_loaders = bears.dataloaders(path)\n",
    "\n",
    "learn = vision_learner(data_loaders, resnet18, metrics=error_rate)\n",
    "learn.fine_tune(4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T01:49:48.763538Z",
     "start_time": "2024-01-03T01:49:47.748817Z"
    }
   },
   "id": "a902a01a9e114d4e",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "학습 완료 후 모델 오차 행렬 파악"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca096b7047cabe95"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m interp \u001B[38;5;241m=\u001B[39m ClassificationInterpretation\u001B[38;5;241m.\u001B[39mfrom_learner(\u001B[43mlearn\u001B[49m)\n\u001B[1;32m      2\u001B[0m interp\u001B[38;5;241m.\u001B[39mplot_confusion_matrix()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'learn' is not defined"
     ]
    }
   ],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T01:58:27.588548Z",
     "start_time": "2024-01-03T01:58:27.583388Z"
    }
   },
   "id": "6d16ebe0aab224c6",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c3a92fe72b68409"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
